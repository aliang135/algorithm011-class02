# Week02总结：

## 学习笔记

### 面试时做题四件套：

1. clarification
2. Possible solutions --> optimal (time & space)
3. code
4. Test cases

### 二叉树(Binary Tree)

每个节点最多只有两个子节点。

二叉树的遍历, 看根节点的位置:

- 前序, 根左右
- 中序, 左根右
- 后序, 左右根

查找一个元素的时间复杂度: O(n)

### 二叉搜索树(Binary Search Tree)：

二叉搜索树，也称二叉排序树，有序二叉树(Ordered Binary Tree)，排序二叉树(Sorted Binary Tree)，是指一颗空树或者具有下列性质的二叉树：

1. 左子树上所有结点的值均小于它的根结点的值；
2. 右子树上所有结点的值均大于它的根结点的值；
3. 以此类推：左、右子树也分别为二叉搜索树。（这就是重复性！）

二叉树**中序遍历**得到的列表中的元素是按**升序排列**

查询，插入和删除的时间复杂度都是O(logn)。

删除拥有左右节点的根结点时，需要吧左边最大（左子树的最右边）或者右边最小的节点（右子树的最左边）提升为根结点。

### 堆(heap)：

可以迅速找到一堆数中的最大或最小的数据结构。

根结点最大的堆叫做大顶堆或大根堆，根结点最小的堆叫做小顶堆或小根堆。常见的堆又二叉堆，斐波那契堆等。

假设时大顶堆，则常见操作：

Find-max: O(1)

Delete-max: O(logN)

insert(create): O(logN) or O(1)

#### 二叉堆实现细节：

1. 二叉堆一般是通过“数组”来实现；

2. 假设“第一个元素”在数组中的索引为0的话，则父节点和子节点的位置关系如下：

   1) 索引为i的左孩子的索引是(2*i+1)；

   2) 索引为i的右孩子的索引是(2*i+2)；

   3) 索引为i的父节点的索引时floor((i-1)/2)。

##### Insert插入操作：

1. 新元素一律先插入到堆的尾部
2. 依次向上调整整个堆堆结构（一直到根即可）。HeapifyUp

##### Delete Max删除堆顶操作：

1. 将堆尾元素替换到顶部（即堆顶被替换删除掉）
2. 依次从根部向下调整整个堆堆结构（一直到堆尾即可）HeapifyDown

### 图 Graph(V,E)：

包括点（V-vertex）和边（E-edge）

#### 点（V-vertex）：

1. 度-入度和出度（点连了多少个边，如果边是无向的，则入度等于出度）

2. 点与点之间：连通与否

#### 边（E-edge）：

1. 有向和无向（单行线）
2. 权重（边长）

## HashMap总结：

### HashMap的底层结构是什么？

在JDK 1.8中，HashMap的底层是由“数组+链表+红黑树”组成，而在JDK1.8之前是由“数组+链表”组成。这样做的目的是为了提升在hash冲突严重时（链表过长）的查找性能，使用链表的查找性能是O(n)，而使用红黑树是O(logn)。

![image](https://github.com/rainism0329/algorithm011-class02/blob/master/Week_02/images/structure.jpeg)

### 什么时候用链表？什么时候用红黑树？

对于插入，默认情况下是使用链表节点，当同一个索引位置的节点在新增后达到9个（阈值8）：如果此时数组长度大于等于 64，则会触发链表节点转红黑树节点（treeifyBin）；而如果数组长度小于64，则不会触发链表转红黑树，而是会进行扩容，因为此时的数据量还比较小。

对于移除，当同一个索引位置的节点在移除后达到 6 个，并且该索引位置的节点为红黑树节点，会触发红黑树节点转链表节点（untreeify）。

### 为什么链表转红黑树阈值为8？

平时在进行方案设计时，必须考虑的两个很重要的因素是：时间和空间。对于 HashMap 也是同样的道理，简单来说，阈值为8是在时间和空间上权衡的结果。红黑树节点大小约为链表节点的2倍，在节点太少时，红黑树的查找性能优势并不明显，付出2倍空间的代价作者觉得不值得。理想情况下，使用随机的哈希码，节点分布在 hash 桶中的频率遵循泊松分布，按照泊松分布的公式计算，链表中节点个数为8时的概率为 0.00000006，这个概率足够低了，并且到8个节点时，红黑树的性能优势也会开始展现出来，因此8是一个较合理的数字。

### 为什么转回链表节点是用的6而不是复用8？

如果设置节点多于8个转红黑树，少于8个就马上转链表，当节点个数在8徘徊时，就会频繁进行红黑树和链表的转换，造成性能的损耗。

### HashMap 有哪些重要属性？

size：HashMap 已经存储的节点个数。

threshold：扩容阈值，当 HashMap 的个数达到该值，触发扩容。

loadFactor：负载因子，扩容阈值 = 容量 * 负载因子。

### HashMap的插入(put)逻辑是怎样的？

对key的hashCode()做一次散列，然后根据这个散列值计算index（i = (n - 1) & hash），相当于模运算。

如果没有发生碰撞（哈希冲突），则直接放到数组中。

如果碰撞了，以链表的形式挂在数组对应的元素后。

如果因为碰撞导致链表过长(大于等于TREEIFY_THRESHOLD)，就把链表转换成红黑树。

如果节点已经存在就替换old value(保证key的唯一性)。

如果数组中存储的元素达到了阈值(超过负载因子*当前容量)，就要resize（重新调整大小并重新散列）。

![image](https://github.com/rainism0329/algorithm011-class02/blob/master/Week_02/images/put.jpeg)

### HashMap获取(get)的流程？

根据传入key进行hash运算，将运算后的值跟数组长度进行模运算，得出这个key对应数组的位置。

如果key的hash值正好等于数组上这个元素的key的hash值的话，直接返回数组上这个位置的元素。

如果不相等，就在这个节点下挂的树或者链表中查询对应的key（有树或链表的情况下）。

都不符合，返回null。

### HashMap扩容(resize)流程？

![image](https://github.com/rainism0329/algorithm011-class02/blob/master/Week_02/images/resize.jpeg)

### JDK 1.8的进行了哪些优化？

1. 底层数据结构从“数组+链表”改成“数组+链表+红黑树”，主要是优化了 hash 冲突较严重时，链表过长的查找性能：O(n) -> O(logn)。

2. 计算 table 初始容量的方式发生了改变，老的方式是从1开始不断向左进行移位运算，直到找到大于等于入参容量的值；新的方式则是通过“5个移位+或等于运算”来计算。

3. 优化了 hash 值的计算方式，新的只是简单的让高16位参与了运算。

4. 扩容时插入方式从“头插法”改成“尾插法”，避免了并发下的死循环。

5. 扩容时计算节点在新表的索引位置方式从“h & (length-1)”改成“hash & oldCap”，性能可能提升不大，但设计更巧妙、更优雅。



（HashMap总结的部分内容转自「程序员囧辉」的原创文章。原文链接：https://blog.csdn.net/v123411739/java/article/details/106324537）
